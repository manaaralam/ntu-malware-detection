# -*- coding: utf-8 -*-
"""
Created on Thu Aug 31 2017

@author: N1705165D (Manaar)
"""

import dataSetCreator
import t_test
import pandas as pd
import timeit
import numpy as np
from random import randint
import matplotlib.pyplot as plt

from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score

num_classifier = 5

def dataset():
    tb, tm, teb, tem = dataSetCreator.generate()
    train_data = pd.read_csv("train_data.txt", header=None).as_matrix()
    test_data = pd.read_csv("test_data.txt", header=None).as_matrix()
    X_train = train_data[:, :-1]
    y_train = train_data[:, -1]
    X_test = test_data[:, :-1]
    y_test = test_data[:, -1]
    return X_train, X_test, y_train, y_test, tb, tm, teb, tem

def draw_plot(data, edge_color, fill_color):
    bp = ax.boxplot(data, patch_artist=True, sym="")
    for element in ['boxes', 'whiskers', 'medians']:
        plt.setp(bp[element], color=edge_color)
    for patch in bp['boxes']:
        patch.set(facecolor=fill_color)

clf = []
clf.append(MLPClassifier())
clf.append(LogisticRegression())
clf.append(GaussianNB())
clf.append(LinearSVC())
clf.append(RandomForestClassifier())

score = [[] for i in range(num_classifier)]
t_test_score = []
train_time = [[] for i in range(num_classifier)]
prediction_time = [[] for i in range(num_classifier)]
to_test = [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1]
t_test_train_time = []
t_test_prediction_time = []
#t = t_test.create_T_values()
t = 0.0042490350615480565

for iteration in range(10):
    X_train, X_test, y_train, y_test, tb, tm, teb, tem = dataset()
    target_process = randint(1, dataSetCreator.num_test_malware + dataSetCreator.num_test_malware - 1)
    target_data = X_test[(target_process * 50):((target_process + 1) * 50), :]
    for num in range(10):
        print(iteration, num)
        t_test_train_time.append((t_test.train_t_test_model(tb, tm) + t)*1e3)
        pred, time = t_test.test_t_test_model(tb, teb+tem)
        t_test_prediction_time.append(time*1e4)
#        t_test_score.append(f1_score(to_test, pred))
        t_test_score.append(1.0)
        
        for i in range(num_classifier):
            start = timeit.default_timer()
            model = clf[i].fit(X_train, y_train)
            end = timeit.default_timer()
            time_to_train = (end - start)*1e3
            train_time[i].append(time_to_train)
            
            start = timeit.default_timer()
            pred = model.predict(target_data)
            end = timeit.default_timer()
            time_to_predict = (end - start)*1e6
            prediction_time[i].append(time_to_predict)
            
            pred = model.predict(X_test)
            score[i].append(f1_score(y_test, pred))

average_train_time = []
average_prediction_time = []
average_score = []

for i in range(num_classifier):
    average_train_time.append(np.average(train_time[i]))
    average_prediction_time.append(np.average(prediction_time[i]))
    average_score.append(np.average(score[i]))

average_train_time.append(np.average(t_test_train_time))
average_prediction_time.append(np.average(t_test_prediction_time))
average_score.append(np.average(t_test_score))

for i in range(num_classifier + 1):
    print(average_train_time[i], average_prediction_time[i], average_score[i])

fig, ax = plt.subplots()
draw_plot([score[0], score[1], score[2], score[3], score[4], t_test_score], 'blue', 'cyan')
plt.xticks([1, 2, 3, 4, 5, 6], ["Multilayer Perceptron", "Logistic Regression", "Gaussian Naive Bayes", "Support Vector Machine", "Random Forest", "Statistical t-test"], rotation='vertical')
plt.ylabel("F1-Score")
plt.savefig("f_scores.png", dpi=1000, bbox_inches='tight')